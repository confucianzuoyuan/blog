= 构建一个编译器
:icons: font
:source-highlighter: pygments
:toc: left
:toclevels: 4
:sectnums:

== 简介

这个系列的文章是一个开发语言的语法分析器和编译器的教程。在我们完成编译器之前，我们将会覆盖构建编译器的每一方面的知识：设计一门新的编程语言，然后构建一个可以工作的编译器。

尽管我不是一个科班出身的计算机科学家（我的博士学位是物理学方面的），我对编译器却已经感兴趣很多年了。我购买了编译器方面的所有书籍并尝试着消化所有的内容。我不介意告诉你这个消化的过程非常的缓慢。编译器方面的书都是写给计算机专业的学生的，而对于我们这些业余爱好者则读起来非常的困难。但经过了很多年的消化，我终于开始学到一点东西了。改变发生于我开始自己鼓捣自己的编译器。现在我决定和你们分享一下我所学到的东西。当这个教程的系列结束时，你当然不可能成为一个计算机科学家，你也不可能学到所有有关编译器的知识。因为我想做的就是忽略掉所有编译器的理论。而你所能学到的就是构建一个可以工作的编译器所需要的方方面面的有关实践的知识。

所以这是一个边做边学的教程。在这一系列教程中，我将会不断的写程序做实验。你最好跟上我的脚步，把我写过的代码自己也写一遍，最好也能添加一些你自己写的代码。我将使用Turbo Pascal 4.0编译器。我将在TP中不断的编写代码。这些代码都是可以执行的代码，可能你会想把这些代码粘贴到你的电脑上然后运行。如果你没有一份Turbo Pascal的拷贝，那么可能会影响你写代码的进程。你最好搞一份拷贝。毕竟，这是一个伟大的产品，能用在很多的地方。

一些有关编译器的文章会包含一些示例代码，或者包含一个完整的编译器代码（例如Small-C编译器），然后你可以拷贝代码然后运行，但无法理解整个代码是如何工作的。我希望做的比那些文章多一些。我希望能教给你如何搞定这些东西，然后你就可以自己搞定这一切，甚至可以鼓捣自己的编译器，或者改进我写的编译器，而不只是重复一遍我的工作。

毫无疑问写一个编译器是一个很有野心的工作，所以不可能一页纸就搞定。我希望在一系列的文章中把这些工作搞定。每一篇文章将会覆盖编译器的某个单独的主题，这些主题独立性很强。如果你某个时间段只对某个主题感兴趣，那你只需要看那个主题的文章就可以了。每篇文章都比较完整，所以在最终完成之前，你只需要等待最新的文章就可以了。所以请耐心。

我的系列教程将不会讲解编译器理论涉及到的很多的方面。正统的编译器课本会遵循以下教学过程：

* 一个介绍性的章节，用来介绍什么是编译器。
* 一个或者两个章节，用来介绍编程语法方面的东西，使用巴科斯-诺尔范式（Backus-Naur Form，BNF）。
* 一个或者两个章节，用来介绍词法分析。重点讲解确定性和非确定性有限自动机。
* 多个章节。用来介绍语法分析理论，从自顶向下递归下降语法分析开始，到LALR语法分析器结束。
* 一个章节，用来介绍中间语言。重点介绍P-code，以及相似的逆波兰表示形式。
* 多个章节。用来介绍处理子程序、传递参数和类型声明的多种方式。
* 一个章节。用来介绍代码生成。通常针对一个拥有简单指令集的虚拟CPU生成代码。大部分读者（事实上，大部分大学的课程）都不会走到这么远。
* 最后的一个或者两个章节。用来介绍优化。读者通常也不会走到这一章。

在我的系列教程中，我将会走一条很不同的路线。我不会给你很多的技术选项，我只会给你一条路。如果你想探索编译器技术各阶段的各种实现技术，好吧，我会鼓励你这么做，但我只会教你我会的那一条路。我也会跳过很多会让人昏昏欲睡的理论知识。别误解我：我并不是鄙视理论，只是当我们去探索一门给定的编程语言的充满各种奇技淫巧的实现时，才会需要理论。但我一直坚信，我们先得把最终要的事情搞定。在教程中，我们将会搞定95%的编译器方面的技术，而这些是不需要那么多理论就能搞定的。

我将会只讨论一种语法分析技术：自顶向下递归下降语法分析器。这个技术是手工打造一个编译器所能使用的唯一的一种技术。如果使用其他方法实现语法分析器，那你就必须使用工具了，例如YACC。而且使用工具的话，我们无法控制最终的编译器会消耗多少内存。

我也借鉴了Ron Cain写的书的部分内容，他是Small C的作者。很多编译器的作者都会使用一种中间语言（例如P-code），也就是将编译器分割成两部分（一个是编译器的前端，用来将代码编译成P-code，一个是编译器的后端，用来将P-code编译成目标机器的指令集代码）。Ron给我们展示了一种方法，那就是我们可以直接将代码编译成目标机器的可执行代码（也就是目标机器的汇编语言程序）。当然编译成的汇编语言代码肯定不是最紧凑的代码，因为编译出紧凑的代码，也就是优化是一个很难的工作。但编译出来的汇编代码是可以工作的，这就够了。当然我也不想让你们觉得我们写的编译器是毫无价值的，所以我会告诉你一些优化的方法。

最后，我会在教程中使用一些技巧，来帮助我们理解编译器的构造过程。这里面我使用的最主要的技巧就是单字符token（token里没有空格）的使用。因为我发现一旦我能够写出一个识别I-T-L这些token的语法分析器，那么写一个识别IF-THEN-ELSE的语法分析器就很简单了。在第二课中，我会向你展示如何编写一个语法分析器来识别任意长度的token。还有一个技巧，就是我会忽略掉文件I/O，因为我发现如果我能够处理来自键盘的输入以及将结果输出到屏幕上，我就可以处理来自硬盘的文件读写。经验表明，如果一个翻译器可以正常工作，那么将翻译器和文件I/O连接起来将会很简单。最后一个技巧就是，我不会去做错误处理和错误恢复方面的工作。我们编写的程序将会识别错误，但不会崩溃，而是直接停止运行，停止的位置是编译器发现的第一个错误，就像Turbo Pascal做的那样。你也可以发明一些其他的技巧。这些技巧不会出现在编译器的课本里，但他们很好使。

有关编程风格和效率的一点补充。就像你看到的那样，我写代码倾向于写非常小而且容易理解的代码片段。我所写的代码不会超过15到20行。我是KISS（keep it simple，sidney）的忠实信徒。所以当简单的代码能搞定时，我不会写技巧性很强或者很复杂的代码。这样写代码或许效率不够高？或许吧，但你会喜欢这样的风格的。就像Brian Kernighan所说的那样，先把代码跑起来，再去让代码跑的更快。如果后面你再想去优化之前所写的代码，你可以这样去做，因为之前写的代码很容易理解。如果你要这样做，那么最好在代码都能跑起来时，再去这样做。

我写代码还有一个倾向就是直到我需要时，我才会去构建一个模块。想要预测未来碰到的所有的情况，会把人逼疯，而且很容易出错。在现在这个充满了好用的编辑器和快速的编译器的时代，如果需要，我会毫不犹豫的重构一个模块。到那时候，我可能才会写出我真正想要的代码。

最后一点：我们这里所遵循的原则是不和P-code以及虚拟CPU指令集搞在一起。当我们写完第一天的代码，我们的代码就可以产生可执行的汇编代码。不过你可能并不喜欢我这里选择的汇编语言：68000汇编语言。我电脑运行的就是这种汇编语言。但是你会发现，将我们的代码修改成能够编译出80x86汇编语言代码的程序，也是很容易的，所以我不觉得这是一个问题。实际上，我很希望某个熟悉8086汇编语言的朋友能够写一份和我的代码所对应的编译器。因为这正是我们所需要的。

摇篮代码

每一个程序都有一些固定的写法...I/O的处理，错误信息的处理等等。我们要写的程序也不例外。我会尽可能将这些样板代码浓缩到最小，这样我们可以集中精力写最重要的部分，而不是迷失在样板代码中。下面的代码就是我们要写出的一些样板代码。包括I/O程序，错误处理程序，一个骨架程序和主程序。我把这些程序叫做我们的摇篮（cradle）。当我们编写其他程序时，会把它们添加到摇篮里面，然后添加一些对这些程序的调用程序。拷贝一份摇篮程序吧，因为我们会在多处使用这些代码。

有很多种方法来组织一个语法分析器的扫描活动。在Unix系统中，人们倾向于使用getc方法和ungetc方法来读取和回退字符。我这里使用的方法是，用一个单独的全局变量来记录向前看到的一个字符。初始化的部分（唯一的一个初始化部分）读取输入流中的第一个字符。我们没有用到Turbo 4.0的任何的特殊的技术。每个接下来的GetChar方法的调用，都将读取输入流中的下一个字符。

[source,pascal]
----
program Cradle;

{ 声明常量 }

const TAB = ^I;

{ 声明变量 }

var Look: char;              { 向前看字符 }
                              
{ 从输入流中读取新的字符 }

procedure GetChar;
begin
   Read(Look);
end;

{ 打印错误信息 }

procedure Error(s: string);
begin
   WriteLn;
   WriteLn(^G, 'Error: ', s, '.');
end;

{ 打印错误信息然后将程序挂起 }

procedure Abort(s: string);
begin
   Error(s);
   Halt;
end;

{ 打印预期看到的信息 }

procedure Expected(s: string);
begin
   Abort(s + ' Expected');
end;

{ 匹配一个特定的输入字符 }

procedure Match(x: char);
begin
   if Look = x then GetChar
   else Expected('''' + x + '''');
end;

{ 识别一个字母 }

function IsAlpha(c: char): boolean;
begin
   IsAlpha := upcase(c) in ['A'..'Z'];
end;

{ 识别一个十进制数字 }

function IsDigit(c: char): boolean;
begin
   IsDigit := c in ['0'..'9'];
end;

{ 获取一个标识符 }

function GetName: char;
begin
   if not IsAlpha(Look) then Expected('Name');
   GetName := UpCase(Look);
   GetChar;
end;

{ 获取一个数值 }

function GetNum: char;
begin
   if not IsDigit(Look) then Expected('Integer');
   GetNum := Look;
   GetChar;
end;

{ 输出一个带有制表符TAB的字符串 }

procedure Emit(s: string);
begin
   Write(TAB, s);
end;

{ 输出带有制表符TAB和CRLF字符的字符串 }

procedure EmitLn(s: string);
begin
   Emit(s);
   WriteLn;
end;

{ 初始化 }

procedure Init;
begin
   GetChar;
end;

{ 主程序 }

begin
   Init;
end.
----

简介结束了。将上面的代码拷贝到TP中，然后编译它们。要保证编译能够通过然后正确的运行起来。接下来我们将要开始第一课，也就是表达式的语法分析。

NOTE: 如果在Ubuntu下想要进行Pascal编程，可以 `sudo apt-get install fpc` 。

== 对表达式进行语法分析

让我们开始吧！

如果你已经阅读了简介这一章，你就知道我们要干什么了。你也应该已经将摇篮代码都拷贝到你的Turbo Pascal软件中了，并且还编译过了。现在我们可以开始了。

我们这篇文章将要学习如何来对数学表达式进行语法分析，以及如何将数学表达式翻译成68000汇编代码。我们预期的输出是一系列的汇编语句，而汇编语句的执行结果是正确的计算结果。一个表达式就是等式的右边，如下：

[source,text]
----
               x = 2*y + 3/(4*z)
----

在早期阶段，我的步子会迈的非常非常小。这样初学者不会迷失。有一些很好的课程需要我们在很早的时候就学会，这样我们后面会很容易学习其他的知识。对于有经验的读者，需要忍受一下我讲的一些非常基础的知识。我们很快就会进入到核心区域的知识。

单字符的数字

为了保持教程一贯的风格（KISS，还记得吗？），让我们先从绝对最简单的情况开始思考。对于我来说，就是一个表达式只包含一个单个字符的数字的这种情况。

在开始写代码之前，要保证你将上一章的摇篮代码已经拷贝到你的Turbo Pascal中了。我们在别的代码中将会再次使用它们。接下来将下面的代码添加到程序中：

[source,pascal]
----
{---------------------------------------------------------------}
{ Parse and Translate a Math Expression }

procedure Expression;
begin
   EmitLn('MOVE #' + GetNum + ',D0')
end;
{---------------------------------------------------------------}
----

然后将 `Expression;` 这一行添加到主程序当中去，现在主程序如下：
                              
[source,pascal]
----
{---------------------------------------------------------------}
begin
   Init;
   Expression;
end.
{---------------------------------------------------------------}
----

现在运行程序。尝试一下将任意单个数字作为输入。你将会得到一行汇编代码的输出。然后再尝试一下输入任意其他的单个字符，你将会发现我们的语法分析器将会打印一个错误信息。

恭喜你！我们现在已经有一个可以工作的翻译器了！

好吧，我承认上面的代码的功能实在是太弱了。但是你别小看它啊。这个小小的编译器所做的事情，其实就是大型编译器所做的事情：它正确的识别合法的程序语句，然后输出正确的可以执行的汇编代码。而且同样重要的是，我们写的这个小小的编译器能够识别不合法的程序语句，然后给出一个有意义的错误信息。你还想要啥自行车？随着我们不断的扩展我们的语法分析器，我们最好能够确保以上两点永远没问题。

上面写的小程序有一些其他的特点值得聊一下。首先，你会看到我们并没有将语法分析和代码生成分开成不同的模块。一旦语法分析器知道我们想要的工作已经完成，就会立即生成目标汇编代码。在一个真实的编译器中，GetChar会从磁盘上读取文件，然后输出到另一个磁盘文件。但我们所用的方法很容易进行测试和实验。

同时也要注意，一个表达式一定会产生一个求值结果，并将求值结果存放到某个地方。我选择的地方是68000芯片的D0寄存器。我可能应该选其他的地方来存放求值结果，但D0也很好。

二元表达式

现在我们已经上路了，让我们继续往前开车。必须要承认的是，一个表达式只包含一个数字，够呛能满足我们的需求。所以让我们看一下如何来扩展我们的代码。假设我们想处理下面这种形式的表达式：

[source,text]
----
                         1+2
     或者                4-3
     或者, 更一般的形式, <term> +/- <term>
----

NOTE: 其实上面的最后一行就是巴科斯-诺尔范式，或者简称BNF。
                              
我们需要写一个程序来识别上面所写的 `term` 然后将计算结果存放在某个地方，然后还得写一个程序来识别 `+` 和 `-` ，然后输出我们想要的汇编代码。但是如果表达式将计算结果保存在 `D0` 寄存器，那我们将 `Term` 的计算结果保存在哪里？答案就是：同样的地方 `D0` 。在我们得到 `Term` 的下一个计算结果之前，我们将会把 `Term` 的第一个计算结果存放在某个地方。

好吧，我们想做的事情基本就是写一个 `Term` 程序，它要做的事情就是我们之前写的 `Expression` 程序要做的事情。所以将 `Expression` 程序 **重命名** 成 `Term` 就行了。然后编写新版本的 `Expression` 程序如下：

[source,pascal]
----
{---------------------------------------------------------------}
{ Parse and Translate an Expression }

procedure Expression;
begin
   Term;
   EmitLn('MOVE D0,D1');
   case Look of
    '+': Add;
    '-': Subtract;
   else Expected('Addop');
   end;
end;
{--------------------------------------------------------------}
----

紧接着，在 `Expression` 程序上面写如下两个程序：

[source,pascal]
----
{--------------------------------------------------------------}
{ Recognize and Translate an Add }

procedure Add;
begin
   Match('+');
   Term;
   EmitLn('ADD D1,D0');
end;


{-------------------------------------------------------------}
{ Recognize and Translate a Subtract }

procedure Subtract;
begin
   Match('-');
   Term;
   EmitLn('SUB D1,D0');
end;
{-------------------------------------------------------------}
----                              

When you're finished with that,  the order of the routines should
be:

 o Term (The OLD Expression)
 o Add
 o Subtract
 o Expression

Now run the program.  Try any combination you can think of of two
single digits,  separated  by  a  '+' or a '-'.  You should get a
series of four assembler-language instructions out  of  each run.
Now  try  some  expressions with deliberate errors in them.  Does
the parser catch the errors?

Take  a  look  at the object  code  generated.    There  are  two
observations we can make.  First, the code generated is  NOT what
we would write ourselves.  The sequence

        MOVE #n,D0
        MOVE D0,D1

is inefficient.  If we were  writing  this code by hand, we would
probably just load the data directly to D1.

There is a  message  here:  code  generated by our parser is less
efficient  than the code we would write by hand.  Get used to it.
That's going to be true throughout this series.  It's true of all
compilers to some extent.  Computer scientists have devoted whole
lifetimes to the issue of code optimization, and there are indeed
things that can be done to improve the quality  of  code  output.
Some compilers do quite well, but  there  is a heavy price to pay
in complexity, and it's  a  losing  battle  anyway ... there will
probably never come a time when  a  good  assembler-language pro-
grammer can't out-program a compiler.    Before  this  session is
over, I'll briefly mention some ways that we can do a  little op-
timization,  just  to  show you that we can indeed improve things
without too much trouble.  But remember, we're here to learn, not
to see how tight we can make  the  object  code.    For  now, and
really throughout  this  series  of  articles,  we'll  studiously
ignore optimization and  concentrate  on  getting  out  code that
works.

Speaking of which: ours DOESN'T!  The code is _WRONG_!  As things
are working  now, the subtraction process subtracts D1 (which has
the FIRST argument in it) from D0 (which has the second).  That's
the wrong way, so we end up with the wrong  sign  for the result.
So let's fix up procedure Subtract with a  sign-changer,  so that
it reads


{-------------------------------------------------------------}
{ Recognize and Translate a Subtract }

procedure Subtract;
begin
   Match('-');
   Term;
   EmitLn('SUB D1,D0');
   EmitLn('NEG D0');
end;
{-------------------------------------------------------------}


Now  our  code  is even less efficient, but at least it gives the
right answer!  Unfortunately, the  rules that give the meaning of
math expressions require that the terms in an expression come out
in an inconvenient  order  for  us.    Again, this is just one of
those facts of life you learn to live with.   This  one will come
back to haunt us when we get to division.

OK,  at this point we have a parser that can recognize the sum or
difference of two digits.    Earlier,  we  could only recognize a
single digit.  But  real  expressions can have either form (or an
infinity of others).  For kicks, go back and run the program with
the single input line '1'.

Didn't work, did it?   And  why  should  it?    We  just finished
telling  our  parser  that the only kinds of expressions that are
legal are those  with  two  terms.    We  must  rewrite procedure
Expression to be a lot more broadminded, and this is where things
start to take the shape of a real parser.




GENERAL EXPRESSIONS

In the  REAL  world,  an  expression  can  consist of one or more
terms, separated  by  "addops"  ('+'  or  '-').   In BNF, this is
written

          <expression> ::= <term> [<addop> <term>]*


We  can  accomodate  this definition of an  expression  with  the
addition of a simple loop to procedure Expression:


{---------------------------------------------------------------}
{ Parse and Translate an Expression }

procedure Expression;
begin
   Term;
   while Look in ['+', '-'] do begin
      EmitLn('MOVE D0,D1');
      case Look of
       '+': Add;
       '-': Subtract;
      else Expected('Addop');
      end;
   end;
end;
{--------------------------------------------------------------}


NOW we're getting somewhere!   This version handles any number of
terms, and it only cost us two extra lines of code.  As we go on,
you'll discover that this is characteristic  of  top-down parsers
... it only takes a few lines of code to accomodate extensions to
the  language.    That's  what  makes  our  incremental  approach
possible.  Notice, too, how well the code of procedure Expression
matches the BNF definition.   That, too, is characteristic of the
method.  As you get proficient in the approach, you'll  find that
you can turn BNF into parser code just about as  fast  as you can
type!

OK, compile the new version of our parser, and give it a try.  As
usual,  verify  that  the  "compiler"   can   handle   any  legal
expression,  and  will  give a meaningful error  message  for  an
illegal one.  Neat, eh?  You might note that in our test version,
any error message comes  out  sort of buried in whatever code had
already been  generated. But remember, that's just because we are
using  the  CRT  as  our  "output  file"  for   this   series  of
experiments.  In a production version, the two  outputs  would be
separated ... one to the output file, and one to the screen.


USING THE STACK

At  this  point  I'm going to  violate  my  rule  that  we  don't
introduce any complexity until  it's  absolutely  necessary, long
enough to point out a problem with the code we're generating.  As
things stand now, the parser  uses D0 for the "primary" register,
and D1 as  a place to store the partial sum.  That works fine for
now,  because  as  long as we deal with only the "addops" '+' and
'-', any new term can be added in as soon as it is found.  But in
general that isn't true.  Consider, for example, the expression

               1+(2-(3+(4-5)))
                              
If we put the '1' in D1, where  do  we  put  the  '2'?    Since a
general expression can have any degree of complexity, we're going
to run out of registers fast!

Fortunately,  there's  a  simple  solution.    Like  every modern
microprocessor, the 68000 has a stack, which is the perfect place
to save a variable number of items. So instead of moving the term
in D0 to  D1, let's just push it onto the stack.  For the benefit
of  those unfamiliar with 68000 assembler  language,  a  push  is
written

               -(SP)

and a pop,     (SP)+ .


So let's change the EmitLn in Expression to read:

               EmitLn('MOVE D0,-(SP)');

and the two lines in Add and Subtract to

               EmitLn('ADD (SP)+,D0')

and            EmitLn('SUB (SP)+,D0'),

respectively.  Now try the parser again and make sure  we haven't
broken it.

Once again, the generated code is less efficient than before, but
it's a necessary step, as you'll see.


MULTIPLICATION AND DIVISION

Now let's get down to some REALLY serious business.  As  you  all
know,  there  are  other  math   operators   than   "addops"  ...
expressions can also have  multiply  and  divide operations.  You
also  know  that  there  is  an implied operator  PRECEDENCE,  or
hierarchy, associated with expressions, so that in  an expression
like

                    2 + 3 * 4,

we know that we're supposed to multiply FIRST, then  add.    (See
why we needed the stack?)

In the early days of compiler technology, people used some rather
complex techniques to insure that the  operator  precedence rules
were  obeyed.    It turns out,  though,  that  none  of  this  is
necessary ... the rules can be accommodated quite  nicely  by our
top-down  parsing technique.  Up till now,  the  only  form  that
we've considered for a term is that of a  single  decimal  digit.

More generally, we  can  define  a  term as a PRODUCT of FACTORS;
i.e.,

          <term> ::= <factor>  [ <mulop> <factor ]*

What  is  a factor?  For now, it's what a term used to be  ...  a
single digit.

Notice the symmetry: a  term  has the same form as an expression.
As a matter of fact, we can  add  to  our  parser  with  a little
judicious  copying and renaming.  But  to  avoid  confusion,  the
listing below is the complete set of parsing routines.  (Note the
way we handle the reversal of operands in Divide.)


{---------------------------------------------------------------}
{ Parse and Translate a Math Factor }

procedure Factor;
begin
   EmitLn('MOVE #' + GetNum + ',D0')
end;


{--------------------------------------------------------------}
{ Recognize and Translate a Multiply }

procedure Multiply;
begin
   Match('*');
   Factor;
   EmitLn('MULS (SP)+,D0');
end;


{-------------------------------------------------------------}
{ Recognize and Translate a Divide }

procedure Divide;
begin
   Match('/');
   Factor;
   EmitLn('MOVE (SP)+,D1');
   EmitLn('DIVS D1,D0');
end;


{---------------------------------------------------------------}
{ Parse and Translate a Math Term }

procedure Term;
begin
   Factor;
   while Look in ['*', '/'] do begin
      EmitLn('MOVE D0,-(SP)');
      case Look of
       '*': Multiply;
       '/': Divide;
      else Expected('Mulop');
      end;
   end;
end;




{--------------------------------------------------------------}
{ Recognize and Translate an Add }

procedure Add;
begin
   Match('+');
   Term;
   EmitLn('ADD (SP)+,D0');
end;


{-------------------------------------------------------------}
{ Recognize and Translate a Subtract }

procedure Subtract;
begin
   Match('-');
   Term;
   EmitLn('SUB (SP)+,D0');
   EmitLn('NEG D0');
end;


{---------------------------------------------------------------}
{ Parse and Translate an Expression }

procedure Expression;
begin
   Term;
   while Look in ['+', '-'] do begin
      EmitLn('MOVE D0,-(SP)');
      case Look of
       '+': Add;
       '-': Subtract;
      else Expected('Addop');
      end;
   end;
end;
{--------------------------------------------------------------}


Hot dog!  A NEARLY functional parser/translator, in only 55 lines
of Pascal!  The output is starting to look really useful,  if you
continue to overlook the inefficiency,  which  I  hope  you will.
Remember, we're not trying to produce tight code here.


PARENTHESES

We  can  wrap  up this part of the parser with  the  addition  of
parentheses with  math expressions.  As you know, parentheses are
a  mechanism to force a desired operator  precedence.    So,  for
example, in the expression

               2*(3+4) ,

the parentheses force the addition  before  the  multiply.   Much
more importantly, though, parentheses  give  us  a  mechanism for
defining expressions of any degree of complexity, as in

               (1+2)/((3+4)+(5-6))

The  key  to  incorporating  parentheses  into our parser  is  to
realize that  no matter how complicated an expression enclosed by
parentheses may be,  to  the  rest  of  the world it looks like a
simple factor.  That is, one of the forms for a factor is:

          <factor> ::= (<expression>)

This is where the recursion comes in. An expression can contain a
factor which contains another expression which contains a factor,
etc., ad infinitum.

Complicated or not, we can take care of this by adding just a few
lines of Pascal to procedure Factor:
                             

{---------------------------------------------------------------}
{ Parse and Translate a Math Factor }

procedure Expression; Forward;

procedure Factor;
begin
   if Look = '(' then begin
      Match('(');
      Expression;
      Match(')');
      end
   else
      EmitLn('MOVE #' + GetNum + ',D0');
end;
{--------------------------------------------------------------}


Note again how easily we can extend the parser, and how  well the
Pascal code matches the BNF syntax.

As usual, compile the new version and make sure that it correctly
parses  legal sentences, and flags illegal  ones  with  an  error
message.


UNARY MINUS

At  this  point,  we have a parser that can handle just about any
expression, right?  OK, try this input sentence:

                         -1

WOOPS!  It doesn't work, does it?   Procedure  Expression expects
everything to start with an integer, so it coughs up  the leading
minus  sign.  You'll find that +3 won't  work  either,  nor  will
something like

                    -(3-2) .

There  are  a  couple of ways to fix the problem.    The  easiest
(although not necessarily the best)  way is to stick an imaginary
leading zero in  front  of  expressions  of this type, so that -3
becomes 0-3.  We can easily patch this into our  existing version
of Expression:



{---------------------------------------------------------------}
{ Parse and Translate an Expression }

procedure Expression;
begin
   if IsAddop(Look) then
      EmitLn('CLR D0')
   else
      Term;
   while IsAddop(Look) do begin
      EmitLn('MOVE D0,-(SP)');
      case Look of
       '+': Add;
       '-': Subtract;
      else Expected('Addop');
      end;
   end;
end;
{--------------------------------------------------------------}
 

I TOLD you that making changes  was  easy!   This time it cost us
only  three  new lines of Pascal.   Note  the  new  reference  to
function IsAddop.  Since the test for an addop appeared  twice, I
chose  to  embed  it in the new function.  The  form  of  IsAddop
should be apparent from that for IsAlpha.  Here it is:


{--------------------------------------------------------------}
{ Recognize an Addop }

function IsAddop(c: char): boolean;
begin
   IsAddop := c in ['+', '-'];
end;
{--------------------------------------------------------------}


OK, make these changes to the program and recompile.   You should
also include IsAddop in your baseline copy of the cradle.   We'll
be needing  it  again  later.   Now try the input -1 again.  Wow!
The efficiency of the code is  pretty  poor ... six lines of code
just for loading a simple constant ... but at least it's correct.
Remember, we're not trying to replace Turbo Pascal here.

At this point we're just about finished with the structure of our
expression parser.   This version of the program should correctly
parse and compile just about any expression you care to  throw at
it.    It's still limited in that  we  can  only  handle  factors
involving single decimal digits.    But I hope that by now you're
starting  to  get  the  message  that we can  accomodate  further
extensions  with  just  some  minor  changes to the parser.   You
probably won't be  surprised  to  hear  that a variable or even a
function call is just another kind of a factor.
                             
In  the next session, I'll show you just how easy it is to extend
our parser to take care of  these  things too, and I'll also show
you just  how easily we can accomodate multicharacter numbers and
variable names.  So you see,  we're  not  far at all from a truly
useful parser.




A WORD ABOUT OPTIMIZATION

Earlier in this session, I promised to give you some hints  as to
how we can improve the quality of the generated code.  As I said,
the  production of tight code is not the  main  purpose  of  this
series of articles.  But you need to at least know that we aren't
just  wasting our time here ... that we  can  indeed  modify  the
parser further to  make  it produce better code, without throwing
away everything we've done to date.  As usual, it turns  out that
SOME optimization is not that difficult to do ... it simply takes
some extra code in the parser.

There are two basic approaches we can take:

  o Try to fix up the code after it's generated

    This is  the concept of "peephole" optimization.  The general
    idea it that we  know  what  combinations of instructions the
    compiler  is  going  to generate, and we also know which ones
    are pretty bad (such as the code for -1, above).    So all we
    do  is  to   scan   the  produced  code,  looking  for  those
    combinations, and replacing  them  by better ones.  It's sort
    of   a   macro   expansion,   in   reverse,   and   a  fairly
    straightforward  exercise  in   pattern-matching.   The  only
    complication,  really, is that there may be  a  LOT  of  such
    combinations to look for.  It's called  peephole optimization
    simply because it only looks at a small group of instructions
    at a time.  Peephole  optimization can have a dramatic effect
    on  the  quality  of the code,  with  little  change  to  the
    structure of the compiler  itself.   There is a price to pay,
    though,  in  both  the  speed,   size, and complexity of  the
    compiler.  Looking for all those combinations calls for a lot
    of IF tests, each one of which is a source of error.  And, of
    course, it takes time.

     In  the  classical  implementation  of a peephole optimizer,
    it's done as a second pass to the compiler.  The  output code
    is  written  to  disk,  and  then  the  optimizer  reads  and
    processes the disk file again.  As a matter of fact,  you can
    see that the optimizer could  even be a separate PROGRAM from
    the compiler proper.  Since the optimizer only  looks  at the
    code through a  small  "window"  of  instructions  (hence the
    name), a better implementation would be to simply buffer up a
    few lines of output, and scan the buffer after each EmitLn.

  o Try to generate better code in the first place
                             
    This approach calls for us to look for  special  cases BEFORE
    we Emit them.  As a trivial example,  we  should  be  able to
    identify a constant zero,  and  Emit a CLR instead of a load,
    or even do nothing at all, as in an add of zero, for example.
    Closer to home, if we had chosen to recognize the unary minus
    in Factor  instead of in Expression, we could treat constants
    like -1 as ordinary constants,  rather  then  generating them
    from  positive  ones.   None of these things are difficult to
    deal with ... they only add extra tests in the code, which is
    why  I  haven't  included them in our program.  The way I see
    it, once we get to the point that we have a working compiler,
    generating useful code  that  executes, we can always go back
    and tweak the thing to tighten up the code produced.   That's
    why there are Release 2.0's in the world.

There IS one more type  of  optimization  worth  mentioning, that
seems to promise pretty tight code without too much hassle.  It's
my "invention" in the  sense  that I haven't seen it suggested in
print anywhere, though I have  no  illusions  that  it's original
with me.

This  is to avoid such a heavy use of the stack, by making better
use of the CPU registers.  Remember back when we were  doing only
addition  and  subtraction,  that we used registers  D0  and  D1,
rather than the stack?  It worked, because with  only  those  two
operations, the "stack" never needs more than two entries.

Well,  the 68000 has eight data registers.  Why not use them as a
privately managed stack?  The key is to recognize  that,  at  any
point in its processing,  the  parser KNOWS how many items are on
the  stack, so it can indeed manage it properly.  We can define a
private "stack pointer" that keeps  track  of  which  stack level
we're at, and addresses the  corresponding  register.   Procedure
Factor,  for  example,  would  not  cause data to be loaded  into
register  D0,  but   into  whatever  the  current  "top-of-stack"
register happened to be.

What we're doing in effect is to replace the CPU's RAM stack with
a  locally  managed  stack  made  up  of  registers.    For  most
expressions, the stack level  will  never  exceed eight, so we'll
get pretty good code out.  Of course, we also  have  to deal with
those  odd cases where the stack level  DOES  exceed  eight,  but
that's no problem  either.    We  simply let the stack spill over
into the CPU  stack.    For  levels  beyond eight, the code is no
worse  than  what  we're generating now, and for levels less than
eight, it's considerably better.

For the record, I  have  implemented  this  concept, just to make
sure  it  works  before  I  mentioned  it to you.  It does.    In
practice, it turns out that you can't really use all eight levels
... you need at least one register free to  reverse  the  operand
order for division  (sure  wish  the  68000 had an XTHL, like the
8080!).  For expressions  that  include  function calls, we would
also need a register reserved for them. Still, there  is  a  nice
improvement in code size for most expressions.

So, you see, getting  better  code  isn't  that difficult, but it
does add complexity to the our translator ...  complexity  we can
do without at this point.  For that reason,  I  STRONGLY  suggest
that we continue to ignore efficiency issues for the rest of this
series,  secure  in  the knowledge that we can indeed improve the
code quality without throwing away what we've done.

Next lesson, I'll show you how to deal with variables factors and
function calls.  I'll also show you just how easy it is to handle
multicharacter tokens and embedded white space.